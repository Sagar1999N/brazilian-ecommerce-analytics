# Base configuration
app {
  name = "Brazilian E-commerce Analytics"
  version = "1.0.0"
  environment = ${?ENV}

  spark {
    master = "local[*]"
    app-name = ${app.name}
    enable-hive-support = false

    # Performance tuning for local development
    config {
      "spark.serializer" = "org.apache.spark.serializer.KryoSerializer"
      "spark.sql.shuffle.partitions" = "4"
      "spark.sql.adaptive.enabled" = "true"
      "spark.sql.legacy.timeParserPolicy" = "LEGACY"
    }
  }

  # Data paths - Medallion Architecture
  data {
    base-dir = "data"

    # Raw data (landing zone)
    raw {
      path = ${app.data.base-dir}"/raw/"
      format = "csv"
    }

    # Bronze layer (raw ingestion, minimal transformation)
    # Note: Your "staging" is effectively Bronze
    bronze {
      path = ${app.data.base-dir}"/bronze/"
      format = "parquet"
    }

    # Silver layer (cleaned, validated, deduplicated)
    silver {
      path = ${app.data.base-dir}"/silver/"
      format = "parquet"
    }

    # Gold layer (business-level aggregates)
    gold {
      path = ${app.data.base-dir}"/gold/"
      format = "parquet"
    }

    # Quarantine (Dead Letter Queue for bad records)
    quarantine {
      path = ${app.data.base-dir}"/quarantine/"
      format = "parquet"
    }

    # Legacy paths (keeping for backward compatibility)
#    staging {
#      path = ${app.data.base-dir}"/staging/"
#      format = "parquet"
#    }
#
#    processed {
#      path = ${app.data.base-dir}"/processed/"
#      format = "parquet"
#    }
#
#    archive {
#      path = ${app.data.base-dir}"/archive/"
#      retention-days = 30
#    }
  }

  # Database configuration
  database {
    postgres {
      host = "localhost"
      port = 5432
      name = "ecommerce"
      user = "ecommerce"
      password = "ecommerce"
      schema = "dw"

      jdbc-url = "jdbc:postgresql://"${app.database.postgres.host}":"${app.database.postgres.port}"/"${app.database.postgres.name}

      pool {
        max-size = 10
        connection-timeout = 30000
        idle-timeout = 600000
        max-lifetime = 1800000
      }
    }
  }

  # Data Quality Configuration
  data-quality {
    # Validation rules
    validation {
      null-check-enabled = true
      duplicate-check-enabled = true
      schema-check-enabled = true
    }

    # Thresholds
    thresholds {
      max-null-percentage = 10.0
      max-duplicate-percentage = 5.0
      min-record-count = 1
    }

    # Quarantine settings
    quarantine {
      enabled = true
      retention-days = 90
    }
  }

  # Logging configuration
  logging {
    level = "INFO"
    path = "logs/"
    pattern = "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"

    # Structured logging for production
    json-output = false
  }

  # Monitoring
  monitoring {
    metrics {
      enabled = true
      port = 9090
      path = "/metrics"
    }

    health-check {
      enabled = true
      interval-seconds = 60
    }
  }
}